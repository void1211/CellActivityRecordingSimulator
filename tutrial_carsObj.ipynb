{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679e5e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tanaka-users\\tlab\\tlab_yasui\\2025\\CellActivityRecordingSimulator\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import spikeinterface as si  # import core only\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.exporters as sexp\n",
    "import spikeinterface.curation as scur\n",
    "import spikeinterface.widgets as sw\n",
    "\n",
    "from probeinterface import generate_multi_columns_probe\n",
    "\n",
    "import cellactivityrecodingsimulator as cars\n",
    "from cellactivityrecodingsimulator.GroundTruthUnitObject import GTUnitObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01bbd19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_job_kwargs = dict(n_jobs=4, chunk_duration=\"1s\")\n",
    "si.set_global_job_kwargs(**global_job_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b4e4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Probe - 96ch - 1shanks"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe = generate_multi_columns_probe(\n",
    "    num_columns=2,\n",
    "    num_contact_per_column=48,\n",
    "    xpitch=6,\n",
    "    ypitch=6,\n",
    "    contact_shapes=\"square\",\n",
    "    contact_shape_params={\"width\": 5},\n",
    "        # contact_shape_params : dict, default: {'radius': 6}\n",
    "        # Parameters for the shape.\n",
    "        # For circle: {\"radius\": float}\n",
    "        # For square: {\"width\": float}\n",
    "        # For rectangle: {\"width\": float, \"height\": float}\n",
    ")\n",
    "device_ids = list(range(probe.get_contact_count()))\n",
    "probe.set_device_channel_indices(device_ids)\n",
    "\n",
    "probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e9bd9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GTUnit - 32 cells - 2 columns"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtunit = GTUnitObject(\n",
    "    num_column=2, \n",
    "    num_unit_per_column=16,\n",
    "    xpitch=25,\n",
    "    ypitch=25,\n",
    "    y_shift_per_column=[0, 12.5],\n",
    "    x_shift=10,\n",
    "    id_major_order=\"row\"\n",
    ")\n",
    "gtunit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c0e2b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ノイズ細胞生成中: 100%|██████████| 3322/3322 [00:02<00:00, 1168.58it/s]\n",
      "ノイズ割振中: 100%|██████████| 96/96 [01:47<00:00,  1.12s/it]\n",
      "100%|██████████| 96/96 [00:01<00:00, 91.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32 units - 96 ch - using noise units"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = Path(\"./\")\n",
    "carsobj = cars.run(\n",
    "    dir=dir_path,\n",
    "    settings=None,\n",
    "    cells=gtunit,\n",
    "    probe=probe\n",
    ")\n",
    "carsobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9db402b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "carsobj.save_npz(dir_path / \"default\" / \"carsobj.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94e0fa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tanaka-users\\tlab\\tlab_yasui\\2025\\CellActivityRecordingSimulator\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:root:Key baseSettings not found in data. Returning default: None\n",
      "WARNING:root:Key spikeSettings not found in data. Returning default: None\n",
      "WARNING:root:Key noiseSettings not found in data. Returning default: None\n",
      "WARNING:root:Key driftSettings not found in data. Returning default: None\n",
      "WARNING:root:Key powerNoiseSettings not found in data. Returning default: None\n",
      "WARNING:root:Key templateSimilarityControlSettings not found in data. Returning default: None\n",
      "Loading cells:   0%|          | 0/32 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cell.from_dict() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcellactivityrecodingsimulator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCarsObject\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CarsObject\n\u001b[0;32m      3\u001b[0m dir_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m carsobj2 \u001b[38;5;241m=\u001b[39m \u001b[43mCarsObject\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_npz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcarsobj.npz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\tlab\\tlab_yasui\\2025\\CellActivityRecordingSimulator\\src\\cellactivityrecodingsimulator\\CarsObject.py:114\u001b[0m, in \u001b[0;36mCarsObject.load_npz\u001b[1;34m(self, file_path)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcells\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m tqdm(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcells\u001b[39m\u001b[38;5;124m'\u001b[39m], desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading cells\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcells\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[1;32m--> 114\u001b[0m         cells\u001b[38;5;241m.\u001b[39mappend(\u001b[43mCell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     cells \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: Cell.from_dict() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from cellactivityrecodingsimulator.CarsObject import CarsObject\n",
    "dir_path = Path(\"./\")\n",
    "carsobj2 = CarsObject().load_npz(file_path=Path(dir_path / \"default\" / \"carsobj.npz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f3aaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>NumpyRecording: 32 channels - 30.0kHz - 1 segments - 300,000 samples - 10.00s - float64 dtype - 73.24 MiB</strong></div><details style='margin-left: 10px;'>  <summary><strong>Channel IDs</strong></summary><ul>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul><li> <strong> is_filtered </strong>: False</li><li> <strong> probe_0_planar_contour </strong>: [[ -25.   43.]\n",
       " [ -25.  -25.]\n",
       " [  21. -125.]\n",
       " [  67.  -25.]\n",
       " [  67.   43.]]</li></details><details style='margin-left: 10px;'><summary><strong>Properties</strong></summary><ul><details><summary><strong>contact_vector</strong></summary>[(0,  0.,  0., 'square', 5., '', '0',  0, 'um', 1., 0., 0., 1.)\n",
       " (0,  0.,  6., 'square', 5., '', '1',  1, 'um', 1., 0., 0., 1.)\n",
       " (0,  0., 12., 'square', 5., '', '2',  2, 'um', 1., 0., 0., 1.)\n",
       " (0,  0., 18., 'square', 5., '', '3',  3, 'um', 1., 0., 0., 1.)\n",
       " (0,  6.,  0., 'square', 5., '', '4',  4, 'um', 1., 0., 0., 1.)\n",
       " (0,  6.,  6., 'square', 5., '', '5',  5, 'um', 1., 0., 0., 1.)\n",
       " (0,  6., 12., 'square', 5., '', '6',  6, 'um', 1., 0., 0., 1.)\n",
       " (0,  6., 18., 'square', 5., '', '7',  7, 'um', 1., 0., 0., 1.)\n",
       " (0, 12.,  0., 'square', 5., '', '8',  8, 'um', 1., 0., 0., 1.)\n",
       " (0, 12.,  6., 'square', 5., '', '9',  9, 'um', 1., 0., 0., 1.)\n",
       " (0, 12., 12., 'square', 5., '', '10', 10, 'um', 1., 0., 0., 1.)\n",
       " (0, 12., 18., 'square', 5., '', '11', 11, 'um', 1., 0., 0., 1.)\n",
       " (0, 18.,  0., 'square', 5., '', '12', 12, 'um', 1., 0., 0., 1.)\n",
       " (0, 18.,  6., 'square', 5., '', '13', 13, 'um', 1., 0., 0., 1.)\n",
       " (0, 18., 12., 'square', 5., '', '14', 14, 'um', 1., 0., 0., 1.)\n",
       " (0, 18., 18., 'square', 5., '', '15', 15, 'um', 1., 0., 0., 1.)\n",
       " (0, 24.,  0., 'square', 5., '', '16', 16, 'um', 1., 0., 0., 1.)\n",
       " (0, 24.,  6., 'square', 5., '', '17', 17, 'um', 1., 0., 0., 1.)\n",
       " (0, 24., 12., 'square', 5., '', '18', 18, 'um', 1., 0., 0., 1.)\n",
       " (0, 24., 18., 'square', 5., '', '19', 19, 'um', 1., 0., 0., 1.)\n",
       " (0, 30.,  0., 'square', 5., '', '20', 20, 'um', 1., 0., 0., 1.)\n",
       " (0, 30.,  6., 'square', 5., '', '21', 21, 'um', 1., 0., 0., 1.)\n",
       " (0, 30., 12., 'square', 5., '', '22', 22, 'um', 1., 0., 0., 1.)\n",
       " (0, 30., 18., 'square', 5., '', '23', 23, 'um', 1., 0., 0., 1.)\n",
       " (0, 36.,  0., 'square', 5., '', '24', 24, 'um', 1., 0., 0., 1.)\n",
       " (0, 36.,  6., 'square', 5., '', '25', 25, 'um', 1., 0., 0., 1.)\n",
       " (0, 36., 12., 'square', 5., '', '26', 26, 'um', 1., 0., 0., 1.)\n",
       " (0, 36., 18., 'square', 5., '', '27', 27, 'um', 1., 0., 0., 1.)\n",
       " (0, 42.,  0., 'square', 5., '', '28', 28, 'um', 1., 0., 0., 1.)\n",
       " (0, 42.,  6., 'square', 5., '', '29', 29, 'um', 1., 0., 0., 1.)\n",
       " (0, 42., 12., 'square', 5., '', '30', 30, 'um', 1., 0., 0., 1.)\n",
       " (0, 42., 18., 'square', 5., '', '31', 31, 'um', 1., 0., 0., 1.)]</details><details><summary><strong>location</strong></summary>[[ 0.  0.]\n",
       " [ 0.  6.]\n",
       " [ 0. 12.]\n",
       " [ 0. 18.]\n",
       " [ 6.  0.]\n",
       " [ 6.  6.]\n",
       " [ 6. 12.]\n",
       " [ 6. 18.]\n",
       " [12.  0.]\n",
       " [12.  6.]\n",
       " [12. 12.]\n",
       " [12. 18.]\n",
       " [18.  0.]\n",
       " [18.  6.]\n",
       " [18. 12.]\n",
       " [18. 18.]\n",
       " [24.  0.]\n",
       " [24.  6.]\n",
       " [24. 12.]\n",
       " [24. 18.]\n",
       " [30.  0.]\n",
       " [30.  6.]\n",
       " [30. 12.]\n",
       " [30. 18.]\n",
       " [36.  0.]\n",
       " [36.  6.]\n",
       " [36. 12.]\n",
       " [36. 18.]\n",
       " [42.  0.]\n",
       " [42.  6.]\n",
       " [42. 12.]\n",
       " [42. 18.]]</details><details><summary><strong>group</strong></summary>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]</details></ul></details>"
      ],
      "text/plain": [
       "NumpyRecording: 32 channels - 30.0kHz - 1 segments - 300,000 samples - 10.00s - float64 dtype \n",
       "                73.24 MiB"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording = carsobj2.get_NumpyRecording([0])\n",
    "# print(recording.get_probes())\n",
    "recording = recording.set_probe(probe)\n",
    "recording\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5d0974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available sorters ['combinato', 'hdsort', 'herdingspikes', 'ironclust', 'kilosort', 'kilosort2', 'kilosort2_5', 'kilosort3', 'kilosort4', 'mountainsort4', 'mountainsort5', 'pykilosort', 'rtsort', 'simple', 'spykingcircus', 'spykingcircus2', 'tridesclous', 'tridesclous2', 'waveclus', 'waveclus_snippets', 'yass']\n",
      "Installed sorters ['simple', 'spykingcircus2', 'tridesclous2']\n"
     ]
    }
   ],
   "source": [
    "print(\"available sorters\", ss.available_sorters())\n",
    "# mountainsort4/5 はwindows非対応．\n",
    "print(\"Installed sorters\", ss.installed_sorters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286afade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from spikeinterface.sorters import run_sorter\n",
    "\n",
    "def find_and_kill_locker(file_path):\n",
    "    \"\"\"\n",
    "    指定されたファイルをロックしているプロセスを特定し、強制終了する関数。\n",
    "    psutilライブラリを使用します。\n",
    "    \"\"\"\n",
    "    target_path = Path(file_path).resolve()\n",
    "    print(f\"Searching for process locking: {target_path}\")\n",
    "\n",
    "    # すべての実行中プロセスを反復処理\n",
    "    for proc in psutil.process_iter(['pid', 'name', 'open_files']):\n",
    "        try:\n",
    "            # プロセスが開いているファイルを確認\n",
    "            if proc.info['open_files']:\n",
    "                for item in proc.info['open_files']:\n",
    "                    if Path(item.path).resolve() == target_path:\n",
    "                        print(f\"Found locking process: PID={proc.pid}, Name={proc.name}\")\n",
    "                        # 強制終了\n",
    "                        proc.kill()\n",
    "                        print(f\"Process PID={proc.pid} has been terminated.\")\n",
    "                        return True\n",
    "        except (psutil.NoSuchProcess, psutil.AccessDenied, FileNotFoundError):\n",
    "            continue\n",
    "    print(\"No process found locking the file.\")\n",
    "    return False\n",
    "\n",
    "def save_with_cleanup(recording, folder, overwrite, n_jobs, total_memory):\n",
    "    \"\"\"\n",
    "    ファイルロックエラー発生時に、ロックしているプロセスを終了させてから\n",
    "    `recording.save()`を再試行するラッパー関数。\n",
    "    \"\"\"\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # save()を実行\n",
    "            return recording.save(folder=folder, overwrite=overwrite, n_jobs=n_jobs, total_memory=total_memory)\n",
    "        except PermissionError as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"PermissionError caught: {e}. Retrying after cleanup...\")\n",
    "                # ロックしているプロセスを特定して終了を試みる\n",
    "                if find_and_kill_locker(folder):\n",
    "                    # プロセス終了後、少し待機して再試行\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "                else:\n",
    "                    # ロッカーが見つからない場合は、手動でディレクトリ削除を試みる\n",
    "                    try:\n",
    "                        shutil.rmtree(folder)\n",
    "                        print(\"Directory manually removed. Retrying save.\")\n",
    "                        time.sleep(1)\n",
    "                        continue\n",
    "                    except PermissionError as manual_e:\n",
    "                        print(f\"Manual removal failed: {manual_e}. The problem persists.\")\n",
    "                        raise manual_e\n",
    "            else:\n",
    "                print(\"Max retries reached. Failing to save.\")\n",
    "                raise e\n",
    "\n",
    "def run_sorter_with_cleanup(sorter_name, recording, folder, **kwargs):\n",
    "    \"\"\"\n",
    "    SpikeInterfaceのsorterを実行し、PermissionErrorが発生した場合は自己修復を試みる。\n",
    "    \"\"\"\n",
    "    output_folder = Path(folder) / f\"{sorter_name}_output\"\n",
    "    max_retries = 3\n",
    "    retries = 0\n",
    "\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            print(f\"Attempting to run sorter: {sorter_name}\")\n",
    "            sorting = run_sorter(sorter_name=sorter_name, recording=recording, folder=folder,\n",
    "                                 remove_existing_folder=True, **kwargs)\n",
    "            return sorting\n",
    "        except PermissionError as e:\n",
    "            print(f\"PermissionError caught: {e}\")\n",
    "            if \"The process cannot access the file\" in str(e):\n",
    "                print(\"File is locked. Attempting to find and kill the locking process.\")\n",
    "                if find_and_kill_locker(output_folder):\n",
    "                    print(\"Locker terminated. Retrying sorter execution.\")\n",
    "                    retries += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"Failed to identify and terminate a locking process. Attempting manual removal.\")\n",
    "                    try:\n",
    "                        shutil.rmtree(output_folder)\n",
    "                        print(\"Directory successfully removed. Retrying sorter execution.\")\n",
    "                        retries += 1\n",
    "                        continue\n",
    "                    except PermissionError:\n",
    "                        print(\"Manual removal failed. The problem persists.\")\n",
    "                        break\n",
    "            else:\n",
    "                raise # Re-raise if it's not the specific file lock error.\n",
    "\n",
    "    raise RuntimeError(\"Failed to run sorter after multiple retries due to persistent file lock issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff401985",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorters = [\"dartsort\",\"kilosort4\", \"spykingcircus2\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6070daa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== dartsort =====\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=4 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=29.30 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tanaka-users\\tlab\\tlab_yasui\\2025\\CellActivityRecordingSimulator\\.venv\\lib\\site-packages\\spikeinterface\\core\\base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n",
      "write_binary_recording (workers: 4 processes): 100%|██████████| 10/10 [00:05<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred: 'dartsort'\n",
      "===== kilosort4 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "noise_level (workers: 4 processes): 100%|██████████| 20/20 [00:00<00:00, 26.94it/s]\n",
      "detect and localize (workers: 4 processes): 100%|██████████| 10/10 [00:00<00:00, 10.53it/s]\n",
      "c:\\Users\\tanaka-users\\tlab\\tlab_yasui\\2025\\CellActivityRecordingSimulator\\.venv\\lib\\site-packages\\spikeinterface\\sortingcomponents\\motion\\motion_utils.py:82: UserWarning: You are trying to estimate motion with `non-rigid` on a probe that is too short!get_spatial_windows(): win_step_um=200.0/win_scale_um=400.0/win_margin_um=-200.0 are too large for the probe size (depth range=18.0). Switching to rigid motion.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tanaka-users\\tlab\\tlab_yasui\\2025\\CellActivityRecordingSimulator\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\tanaka-users\\tlab\\tlab_yasui\\2025\\CellActivityRecordingSimulator\\.venv\\lib\\site-packages\\numpy\\_core\\_methods.py:137: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "c:\\Users\\tanaka-users\\tlab\\tlab_yasui\\2025\\CellActivityRecordingSimulator\\.venv\\lib\\site-packages\\spikeinterface\\core\\base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred: Motion estimation failed. Error given: index 0 is out of bounds for axis 0 with size 0.\n",
      "===== spykingcircus2 =====\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=4 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=29.30 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (workers: 4 processes): 100%|██████████| 10/10 [00:00<00:00, 15.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spykingcircus2 could benefit from using torch. Consider installing it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tanaka-users\\tlab\\tlab_yasui\\2025\\CellActivityRecordingSimulator\\.venv\\lib\\site-packages\\spikeinterface\\core\\sortinganalyzer.py:487: UserWarning: The Recording is not serializable! The recording link will be lost for future load\n",
      "  warnings.warn(\"The Recording is not serializable! The recording link will be lost for future load\")\n",
      "c:\\Users\\tanaka-users\\tlab\\tlab_yasui\\2025\\CellActivityRecordingSimulator\\.venv\\lib\\site-packages\\spikeinterface\\core\\sortinganalyzer.py:487: UserWarning: The Recording is not serializable! The recording link will be lost for future load\n",
      "  warnings.warn(\"The Recording is not serializable! The recording link will be lost for future load\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumpyFolder (NumpyFolderSorting): 38 units - 1 segments - 30.0kHz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "estimate_sparsity (workers: 4 processes): 100%|██████████| 10/10 [00:00<00:00, 189.55it/s]\n",
      "c:\\Users\\tanaka-users\\tlab\\tlab_yasui\\2025\\CellActivityRecordingSimulator\\.venv\\lib\\site-packages\\spikeinterface\\core\\basesorting.py:380: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SortingAnalyzer: 32 channels - 38 units - 1 segments - binary_folder - sparse - has recording\n",
      "Loaded 0 extensions\n"
     ]
    }
   ],
   "source": [
    "# preprocess and run sort and make analyzer\n",
    "sorting_list = []\n",
    "analyzer_list = []\n",
    "dir_name = \"default\"\n",
    "for sorter in sorters:\n",
    "    print(\"=\"*5, sorter, \"=\"*5)\n",
    "    try:\n",
    "        if sorter == \"kilosort4\":\n",
    "            \n",
    "            pp_rec = spre.bandpass_filter(recording, freq_min=300, freq_max=3000)\n",
    "            pp_rec = spre.common_reference(pp_rec, reference=\"global\")\n",
    "            pp_rec = spre.whiten(pp_rec, int_scale=200)\n",
    "            pp_rec = spre.correct_motion(pp_rec, preset=\"kilosort_like\")\n",
    "            pp_rec = pp_rec.save(folder=f\"preprocessed_data_for_{sorter}_{dir_name}\",overwrite=True, n_jobs=8, total_memory=\"2G\")\n",
    "            # pp_rec = save_with_cleanup(pp_rec, folder=f\"preprocessed_data_for_{sorter}_{example_name}_{condition}\", overwrite=True, n_jobs=8, total_memory=\"2G\")\n",
    "            recording_preprocessed = pp_rec\n",
    "        else:\n",
    "            recording_f = spre.bandpass_filter(recording, freq_min=300, freq_max=3000)\n",
    "            recording_cmr = spre.common_reference(recording_f, reference=\"global\", operator=\"median\")\n",
    "            recording_preprocessed = recording_cmr.save(format=\"binary\", folder=f\"preprocessed_data_for_{sorter}_{dir_name}\", overwrite=True)\n",
    "        \n",
    "        sorting = ss.run_sorter(sorter_name=sorter, folder=f\"{sorter}_{dir_name}\" , remove_existing_folder=True, recording=recording_preprocessed)\n",
    "        # sorting = run_sorter_with_cleanup(sorter_name=sorter, folder=f\"{sorter}_{example_name}_{condition}\" , remove_existing_folder=True, recording=recording_preprocessed)\n",
    "        print(sorting)\n",
    "        sorting_list.append(sorting)\n",
    "\n",
    "        analyzer = si.create_sorting_analyzer(sorting=sorting, recording=recording_preprocessed, format='binary_folder', folder=f'analyzer_{sorter}_{dir_name}', overwrite=True)\n",
    "        print(analyzer)\n",
    "        analyzer_list.append(analyzer)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        continue\n",
    "    finally:\n",
    "        if 'pp_rec' in locals():\n",
    "            del pp_rec\n",
    "        if 'recording_preprocessed' in locals():\n",
    "            del recording_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f66c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== dartsort =====\n",
      "['random_spikes', 'waveforms', 'templates', 'noise_levels', 'amplitude_scalings', 'correlograms', 'isi_histograms', 'principal_components', 'spike_amplitudes', 'spike_locations', 'template_metrics', 'template_similarity', 'unit_locations', 'quality_metrics']\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute_waveforms (workers: 4 processes): 100%|██████████| 10/10 [00:02<00:00,  4.64it/s]\n",
      "noise_level (workers: 4 processes): 100%|██████████| 20/20 [00:00<00:00, 20.80it/s]\n",
      "Compute : spike_amplitudes + spike_locations (workers: 4 processes): 100%|██████████| 10/10 [00:00<00:00, 155.13it/s]\n"
     ]
    }
   ],
   "source": [
    "extensions_to_compute = [\n",
    "    \"random_spikes\",\n",
    "    \"waveforms\",\n",
    "    \"noise_levels\",\n",
    "    \"templates\",\n",
    "    \"spike_amplitudes\",\n",
    "    \"unit_locations\",\n",
    "    \"spike_locations\",\n",
    "    \"correlograms\",\n",
    "    \"template_similarity\"\n",
    "]\n",
    "\n",
    "extension_params = {\n",
    "    \"unit_locations\": {\"method\": \"center_of_mass\"},\n",
    "    \"spike_locations\": {\"ms_before\": 0.1},\n",
    "    \"correlograms\": {\"bin_ms\": 0.1},\n",
    "    \"template_similarity\": {\"method\": \"cosine_similarity\"}\n",
    "}\n",
    "try:\n",
    "    if len(analyzer_list) == 0:\n",
    "        for sorter in sorters:\n",
    "            try:\n",
    "                analyzer = si.load_sorting_analyzer(folder=f'analyzer_{sorter}_{dir_name}')\n",
    "                print(\"=\"*5, sorter, \"=\"*5)\n",
    "                possible_extensions = analyzer.get_computable_extensions()\n",
    "                print(possible_extensions)\n",
    "                print(analyzer.has_recording())\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading analyzer: {e}\")\n",
    "                continue\n",
    "    else:\n",
    "        for index, analyzer in enumerate(analyzer_list):\n",
    "            try:\n",
    "                print(\"=\"*5, sorters[index], \"=\"*5)\n",
    "                possible_extensions = analyzer.get_computable_extensions()\n",
    "                print(possible_extensions)\n",
    "                print(analyzer.has_recording())\n",
    "                analyzer.compute(extensions_to_compute, extension_params=extension_params)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading analyzer: {e}\")\n",
    "                continue\n",
    "except NameError:\n",
    "    print(\"No analyzer list found.\")\n",
    "    analyzer_list = []\n",
    "    for sorter in sorters:\n",
    "        try:\n",
    "            analyzer = si.load_sorting_analyzer(folder=f'analyzer_{sorter}_{dir_name}')\n",
    "            print(\"=\"*5, sorter, \"=\"*5)\n",
    "            possible_extensions = analyzer.get_computable_extensions()\n",
    "            print(possible_extensions)\n",
    "            print(analyzer.has_recording())\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading analyzer: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8164640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== dartsort =====\n",
      "Error plotting templates: too many indices for array: array is 1-dimensional, but 2 were indexed\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(analyzer_list)\n",
    "n_unit = 3\n",
    "fig, ax = plt.subplots(n,n_unit)\n",
    "for analyzer_index, analyzer in enumerate(analyzer_list):\n",
    "    try:\n",
    "        print(\"=\"*5, sorters[analyzer_index], \"=\"*5)\n",
    "        for unit_index, unit_id in enumerate(analyzer.unit_ids[:n_unit]):\n",
    "            template = analyzer.get_extension(\"templates\").get_data(operator=\"average\")[unit_index]\n",
    "            ax[analyzer_index,unit_index].plot(template)\n",
    "            ax[analyzer_index,unit_index].set_title(f\"{sorters[analyzer_index]}: unit{unit_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting templates: {e}\")\n",
    "        continue\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a437c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== dartsort =====\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GTUnitObject' object has no attribute 'to_Sorting'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sorting_index, sorting \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sorting_list):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m, sorters[sorting_index], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      4\u001b[0m     comp_gt \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39mcompare_sorter_to_ground_truth(\n\u001b[1;32m----> 5\u001b[0m         gt_sorting\u001b[38;5;241m=\u001b[39m\u001b[43mgtunit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_Sorting\u001b[49m(sampling_frequency\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30000\u001b[39m), \n\u001b[0;32m      6\u001b[0m         tested_sorting\u001b[38;5;241m=\u001b[39msorting, \n\u001b[0;32m      7\u001b[0m         agreement_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m         )\n\u001b[0;32m      9\u001b[0m     comp_gt_list\u001b[38;5;241m.\u001b[39mappend(comp_gt)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(comp_gt)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GTUnitObject' object has no attribute 'to_Sorting'"
     ]
    }
   ],
   "source": [
    "comp_gt_list = []\n",
    "for sorting_index, sorting in enumerate(sorting_list):\n",
    "    print(\"=\"*5, sorters[sorting_index], \"=\"*5)\n",
    "    comp_gt = sc.compare_sorter_to_ground_truth(\n",
    "        gt_sorting=gtunit.to_Sorting(sampling_frequency=30000), \n",
    "        tested_sorting=sorting, \n",
    "        agreement_method=\"count\",\n",
    "        )\n",
    "    comp_gt_list.append(comp_gt)\n",
    "    print(comp_gt)\n",
    "# comp_pair = sc.compare_two_sorters(sorting1=sorting_KS4, sorting2=sorting_SC2)\n",
    "# comp_multi = sc.compare_multiple_sorters(\n",
    "#     sorting_list=[sorting_TDC, sorting_SC2, sorting_KS2], name_list=[\"tdc\", \"sc2\", \"ks2\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a686522",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cell_positions.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gt_unit_positions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcell_positions.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m plot_probe(probe)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(gt_unit_positions[:,\u001b[38;5;241m0\u001b[39m], gt_unit_positions[:,\u001b[38;5;241m1\u001b[39m], c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tanaka-users\\tlab\\tlab_yasui\\2025\\CellActivityRecordingSimulator\\.venv\\lib\\site-packages\\numpy\\lib\\_npyio_impl.py:451\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    449\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 451\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    452\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cell_positions.npy'"
     ]
    }
   ],
   "source": [
    "gt_unit_positions = np.load(dir_path / \"cell_positions.npy\")\n",
    "plot_probe(probe)\n",
    "plt.scatter(gt_unit_positions[:,0], gt_unit_positions[:,1], c=\"red\", s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529ebcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "def compare_spike_times(gt_sorting, tested_sorting, delta_time_ms: float, fs: float, mode: str = \"rate\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compares two lists of spike times and builds a simple agreement matrix.\n",
    "    This function allows for one-to-many matching.\n",
    "\n",
    "    Args:\n",
    "        gt_sorting: The Ground Truth sorting object.\n",
    "        tested_sorting: The tested sorting object.\n",
    "        delta_time_ms (float): The time tolerance for matching, in milliseconds.\n",
    "        fs (float): The sampling frequency in Hz.\n",
    "        mode (str): The mode to calculate matrix. \"rate\" or \"count\".\n",
    "    Returns:\n",
    "        np.ndarray: An agreement matrix where rows correspond to GT units and columns correspond to tested units. The values are the number of matching spikes.\n",
    "    \"\"\"\n",
    "    # Convert delta_time from ms to frames\n",
    "    delta_time_frames = delta_time_ms * fs / 1000\n",
    "\n",
    "    gt_unit_ids = gt_sorting.get_unit_ids()\n",
    "    gt_spike_times = {unit_id: gt_sorting.get_unit_spike_train(unit_id) for unit_id in gt_unit_ids}\n",
    "    tested_unit_ids = tested_sorting.get_unit_ids()\n",
    "    tested_spike_times = {unit_id: tested_sorting.get_unit_spike_train(unit_id) for unit_id in tested_unit_ids}\n",
    "    n_gt = len(gt_unit_ids)\n",
    "    n_tested = len(tested_unit_ids)\n",
    "    TP_matrix = np.zeros((n_gt, n_tested), dtype=int)\n",
    "    FP_matrix = np.zeros((n_gt, n_tested), dtype=int)\n",
    "    FN_matrix = np.zeros((n_gt, n_tested), dtype=int)\n",
    "\n",
    "    # Correct iteration: Iterate through the individual spike time arrays\n",
    "    for i, gt_id in enumerate(gt_unit_ids):\n",
    "        gt_unit_spikes = gt_spike_times[gt_id]\n",
    "        if gt_unit_spikes.size == 0:\n",
    "            continue\n",
    "        \n",
    "        for j, tested_id in enumerate(tested_unit_ids):\n",
    "            tested_unit_spikes = tested_spike_times[tested_id]\n",
    "            if tested_unit_spikes.size == 0:\n",
    "                continue\n",
    "\n",
    "            matches = 0\n",
    "            \n",
    "            # The original code had a bug here.\n",
    "            # It was iterating over a list of arrays, not a single array.\n",
    "            \n",
    "            # Correct logic: for each tested spike, find a match in the GT unit's array\n",
    "            for gt_spike_time in gt_unit_spikes:\n",
    "                # np.searchsorted must be used on a single, 1D array\n",
    "                idx = np.searchsorted(tested_unit_spikes, gt_spike_time)\n",
    "                \n",
    "                found_match = False\n",
    "                if idx < len(tested_unit_spikes) and np.abs(tested_unit_spikes[idx] - gt_spike_time) <= delta_time_frames:\n",
    "                    found_match = True\n",
    "                elif idx > 0 and np.abs(tested_unit_spikes[idx-1] - gt_spike_time) <= delta_time_frames:\n",
    "                    found_match = True\n",
    "                \n",
    "                if found_match:\n",
    "                    matches += 1\n",
    "                    \n",
    "            TP_matrix[i, j] = matches if mode == \"count\" else matches / len(gt_unit_spikes) * 100\n",
    "            FP_matrix[i, j] = len(tested_unit_spikes) - matches if mode == \"count\" else ((len(tested_unit_spikes) - matches) / len(tested_unit_spikes) * 100)\n",
    "            FN_matrix[i, j] = len(gt_unit_spikes) - matches if mode == \"count\" else ((len(gt_unit_spikes) - matches) / len(gt_unit_spikes) * 100)\n",
    "            \n",
    "    return TP_matrix, FP_matrix, FN_matrix\n",
    "\n",
    "def plot_matrix(matrix, title, gt_unit_num, tested_unit_num, ax):\n",
    "    im = ax.imshow(matrix, cmap=\"Blues\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Tested units\")\n",
    "    ax.set_ylabel(\"GT units\")\n",
    "    ax.set_xticks(range(tested_unit_num))\n",
    "    ax.set_yticks(range(gt_unit_num))\n",
    "    \n",
    "    # 各セルに値を書き込む\n",
    "    for i in range(gt_unit_num):\n",
    "        for j in range(tested_unit_num):\n",
    "            text = ax.text(j, i, f'{matrix[i, j]}',\n",
    "                         ha=\"center\", va=\"center\", color=\"red\", fontsize=8)\n",
    "\n",
    "    # Example usage\n",
    "# You need to specify a sampling frequency (fs) and a jitter threshold (delta_time_ms)\n",
    "sampling_frequency = 30000.0  # Hz\n",
    "time_threshold_ms = 1.0      # milliseconds\n",
    "\n",
    "# Calculate the agreement matrix\n",
    "for i, sorting in enumerate(sorting_list):\n",
    "    TP_matrix, FP_matrix, FN_matrix = compare_spike_times(\n",
    "        gt_sorting=gt_sorting,\n",
    "        tested_sorting=sorting,\n",
    "        delta_time_ms=time_threshold_ms,\n",
    "        fs=sampling_frequency,\n",
    "        mode=\"rate\"\n",
    "    )\n",
    "\n",
    "    if len(gt_sorting.get_unit_ids()) > len(sorting_list[i].get_unit_ids()):\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(30,24))\n",
    "    else:\n",
    "        fig, ax = plt.subplots(3, 1, figsize=(24,30))\n",
    "    plot_matrix(TP_matrix, \"TP\", len(gt_sorting.get_unit_ids()), len(sorting_list[i].get_unit_ids()), ax[0])\n",
    "    plot_matrix(FP_matrix, \"FP\", len(gt_sorting.get_unit_ids()), len(sorting_list[i].get_unit_ids()), ax[1])\n",
    "    plot_matrix(FN_matrix, \"FN\", len(gt_sorting.get_unit_ids()), len(sorting_list[i].get_unit_ids()), ax[2])\n",
    "    # fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f5e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_isi(spike_times):\n",
    "    isi = np.diff(spike_times)\n",
    "    return isi\n",
    "\n",
    "def get_isi_violation_rate(spike_times, threshold_ms=2.0, sampling_frequency=30000.0):\n",
    "    isi = get_isi(spike_times)\n",
    "    isi_violation = np.sum(isi < threshold_ms * sampling_frequency / 1000) / len(isi) * 100\n",
    "    return isi_violation\n",
    "\n",
    "def get_isi_violation_rate_by_unit(sorting, threshold_ms=2.0, sampling_frequency=30000.0, dtype=\"dict\"):\n",
    "    isi_violation = {}\n",
    "    for unit_id in sorting.get_unit_ids():\n",
    "        isi_violation[unit_id] = get_isi_violation_rate(sorting.get_unit_spike_train(unit_id), threshold_ms, sampling_frequency)\n",
    "    if dtype == \"dict\":\n",
    "        return isi_violation\n",
    "    elif dtype == \"list\":\n",
    "        return list(isi_violation.values())\n",
    "    else:\n",
    "        ValueError(\"dtype must be 'dict' or 'list'\")\n",
    "\n",
    "def get_single_multi_unit(sorting, threshold_rate=50, threshold_ms=2.0, sampling_frequency=30000.0, unit_type=\"both\"):\n",
    "    single_unit = []\n",
    "    multi_unit = []\n",
    "    isi_violation = get_isi_violation_rate_by_unit(sorting, threshold_ms, sampling_frequency)\n",
    "    unit_ids = sorting.get_unit_ids()\n",
    "    for i, unit_id in enumerate(unit_ids):\n",
    "        if isi_violation[unit_id] > threshold_rate:\n",
    "            multi_unit.append(int(unit_id))\n",
    "        else:\n",
    "            single_unit.append(int(unit_id))\n",
    "\n",
    "    try:    \n",
    "        if unit_type == \"single\":\n",
    "            return single_unit\n",
    "        elif unit_type == \"multi\":\n",
    "            return multi_unit\n",
    "        elif unit_type == \"both\":\n",
    "            return single_unit, multi_unit\n",
    "    except:\n",
    "        ValueError(\"unit_type must be 'single', 'multi', or 'both'\")\n",
    "    \n",
    "        \n",
    "\n",
    "sampling_frequency = 30000.0  # Hz\n",
    "time_threshold_ms = 1.0      # milliseconds\n",
    "mua_threshold_rate = 0.2\n",
    "for i, sorting in enumerate(sorting_list):\n",
    "    isi_violation_dict = get_isi_violation_rate_by_unit(sorting)\n",
    "    isi_violation_values = list(isi_violation_dict.values())\n",
    "    plt.plot(isi_violation_values, label=sorters[i])\n",
    "    print(\"=\"*5, f\"{sorters[i]}\", \"=\"*5, f\"\\n single: {get_single_multi_unit(sorting, threshold_rate=mua_threshold_rate, unit_type=\"single\")}, \\n multi: {get_single_multi_unit(sorting, threshold_rate=mua_threshold_rate, unit_type=\"multi\")}\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ebeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, len(analyzer_list), figsize=(10, 8))\n",
    "for index, analyzer in enumerate(analyzer_list):\n",
    "    unit_locations = analyzer.get_extension(\"unit_locations\").get_data()\n",
    "    [ax[index].scatter(unit_location[0], unit_location[1], alpha=0.7) for unit_location in unit_locations]\n",
    "    ax[index].set_title(f\"Unit Locations - {sorters[index]}\")\n",
    "    ax[index].set_xlabel(\"X coordinate (μm)\")\n",
    "    ax[index].set_ylabel(\"Y coordinate (μm)\")\n",
    "    ax[index].grid(True)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0be705",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, analyzer in enumerate(analyzer_list):\n",
    "    templates = analyzer.get_extension(\"templates\").get_data()\n",
    "    print(templates.shape)\n",
    "    n_templates = len(templates)\n",
    "    n_rows = (n_templates + 3) // 4  # 4列で行数を計算\n",
    "    fig, axes = plt.subplots(n_rows, 4, figsize=(4*4, 4*n_rows))\n",
    "    \n",
    "    # axesを1次元配列に変換\n",
    "    if n_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    axes_flat = axes.flatten()\n",
    "    \n",
    "    for j, template in enumerate(templates):\n",
    "        if j < len(axes_flat):\n",
    "            axes_flat[j].plot(template)\n",
    "            axes_flat[j].set_title(f\"Unit {j}\")\n",
    "            # axes_flat[j].set_xlabel(\"Time (samples)\")\n",
    "            # axes_flat[j].set_ylabel(\"Amplitude\")\n",
    "    \n",
    "    # 使用しないサブプロットを非表示\n",
    "    for j in range(len(templates), len(axes_flat)):\n",
    "        axes_flat[j].set_visible(False)\n",
    "    \n",
    "    # plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96690372",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, analyzer in enumerate(analyzer_list):\n",
    "    # analyzer.compute(\"quality_metrics\")\n",
    "    quality_metrics = analyzer.get_extension(\"quality_metrics\").get_data()\n",
    "    print(quality_metrics[\"isi_violations_ratio\"].shape)\n",
    "    plt.plot(quality_metrics[\"isi_violations_ratio\"])\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93869090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spike_num_by_unit(sorting, dtype=\"dict\"):\n",
    "    spike_num = {}\n",
    "    for unit_id in sorting.get_unit_ids():\n",
    "        spike_num[unit_id] = len(sorting.get_unit_spike_train(unit_id))\n",
    "    if dtype == \"dict\":\n",
    "        return spike_num\n",
    "    elif dtype == \"list\":\n",
    "        return list(spike_num.values())\n",
    "    else:\n",
    "        ValueError(\"dtype must be 'dict' or 'list'\")\n",
    "\n",
    "for i, sorting in enumerate(sorting_list):\n",
    "    isi_violation_list = get_isi_violation_rate_by_unit(sorting, dtype=\"list\")\n",
    "    spike_num_list = get_spike_num_by_unit(sorting, dtype=\"list\")\n",
    "    plt.scatter(spike_num_list, isi_violation_list, label=sorters[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74028137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, comp_gt in enumerate(comp_gt_list):\n",
    "#     print(\"=\"*5, sorters[i], \"=\"*5)\n",
    "#     print(comp_gt.get_performance(method=\"by_unit\"))\n",
    "#     if len(gt_sorting.get_unit_ids()) > len(sorting_list[i].get_unit_ids()):\n",
    "#         fig, ax = plt.subplots(1, 2, figsize=(10,8))\n",
    "#     else:\n",
    "#         fig, ax = plt.subplots(2, 1, figsize=(10,8))\n",
    "        \n",
    "#     # 混同行列\n",
    "#     sw.plot_confusion_matrix(\n",
    "#         comp_gt,\n",
    "#         unit_ticks=True,\n",
    "#         count_text=True,\n",
    "#         ax=ax[0], \n",
    "#     )\n",
    "\n",
    "#     # 合意行列\n",
    "#     w_agr = sw.plot_agreement_matrix(\n",
    "#         comp_gt, \n",
    "#         ordered=False, \n",
    "#         count_text=True, \n",
    "#         unit_ticks=False, \n",
    "#         ax=ax[1],\n",
    "#     )\n",
    "#     ax[0].set_title(f\"{sorters[i]} confusion\")\n",
    "#     ax[1].set_title(f\"{sorters[i]} agreement\")\n",
    "#     fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5e0485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sw.plot_all_amplitudes_distributions(analyzer_list[0])\n",
    "# sw.plot_amplitudes(analyzer_list[0])\n",
    "# sw.plot_autocorrelograms(analyzer_list[0])\n",
    "# # sw.plot_comparison_collision_by_similarity(\n",
    "# #     comp_gt_list[0], \n",
    "# #     templates_array=np.load(dir_path / \"spike_templates.npy\", allow_pickle=True).T,\n",
    "# #     )\n",
    "# sw.plot_crosscorrelograms(analyzer_list[0])\n",
    "# sw.plot_isi_distribution(analyzer_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19c19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sw.plot_multicomparison_agreement(comp_gt_list[0])\n",
    "# sw.plot_multicomparison_agreement_by_sorter(comp_gt_list[0])\n",
    "# sw.plot_multicomparison_graph(comp_gt_list[0])\n",
    "# sw.plot_peak_activity(recording, analyzer_list[0].get_detect_peaks())\n",
    "# sw.plot_probe_map(recording)\n",
    "# # sw.plot_quality_metrics(analyzer_list[0])\n",
    "# sw.plot_rasters(analyzer_list[0])\n",
    "\n",
    "# sw.plot_sorting_summary(analyzer_list[0], backend=\"spikeinterface_gui\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
